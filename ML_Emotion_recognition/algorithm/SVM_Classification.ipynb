{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_labels = [0, 1, 2, 3, 4, 5, 6,7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting FER2013 TO IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-759ff8846e2c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0merrno\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmisc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mdlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimageio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'dlib'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import argparse\n",
    "import errno\n",
    "import scipy.misc\n",
    "import dlib\n",
    "import cv2\n",
    "import imageio\n",
    "from skimage.feature import hog\n",
    "import sys\n",
    "sys.argv=['']\n",
    "del sys\n",
    "# initialization\n",
    "image_height = 48\n",
    "image_width = 48\n",
    "window_size = 24\n",
    "window_step = 6\n",
    "ONE_HOT_ENCODING = False\n",
    "SAVE_IMAGES = False\n",
    "GET_LANDMARKS = False\n",
    "GET_HOG_FEATURES = False\n",
    "GET_HOG_WINDOWS_FEATURES = False\n",
    "SELECTED_LABELS = []\n",
    "IMAGES_PER_LABEL = 500\n",
    "OUTPUT_FOLDER_NAME = \"fer2013_features\"\n",
    "\n",
    "# parse arguments and initialize variables:\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"-j\", \"--jpg\", default=\"no\", help=\"save images as .jpg files\")\n",
    "parser.add_argument(\"-l\", \"--landmarks\", default=\"yes\", help=\"extract Dlib Face landmarks\")\n",
    "parser.add_argument(\"-ho\", \"--hog\", default=\"yes\", help=\"extract HOG features\")\n",
    "parser.add_argument(\"-hw\", \"--hog_windows\", default=\"yes\", help=\"extract HOG features from a sliding window\")\n",
    "parser.add_argument(\"-o\", \"--onehot\", default=\"no\", help=\"one hot encoding\")\n",
    "parser.add_argument(\"-e\", \"--expressions\", default=\"0,1,2,3,4,5,6,7\", help=\"choose the faciale expression you want to use: 0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral\")\n",
    "args = parser.parse_args()\n",
    "if args.jpg == \"yes\":\n",
    "    SAVE_IMAGES = True\n",
    "if args.landmarks == \"yes\":\n",
    "    GET_LANDMARKS = True\n",
    "if args.hog == \"yes\":\n",
    "    GET_HOG_FEATURES = True\n",
    "if args.hog_windows == \"yes\":\n",
    "    GET_HOG_WINDOWS_FEATURES = True\n",
    "if args.onehot == \"yes\":\n",
    "    ONE_HOT_ENCODING = True\n",
    "if args.expressions != \"\":\n",
    "    expressions  = args.expressions.split(\",\")\n",
    "    for i in range(0,len(expressions)):\n",
    "        label = int(expressions[i])\n",
    "        if (label >=0 and label<=7 ):\n",
    "            SELECTED_LABELS.append(label)\n",
    "if SELECTED_LABELS == []:\n",
    "    SELECTED_LABELS = [0,1,2,3,4,5,6,7]\n",
    "print(len(SELECTED_LABELS))\n",
    "print( str(len(SELECTED_LABELS)) + \" expressions\")\n",
    "\n",
    "# loading Dlib predictor and preparing arrays:\n",
    "print( \"preparing\")\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "original_labels = [0, 1, 2, 3, 4, 5, 6,7]\n",
    "new_labels = list(set(original_labels) & set(SELECTED_LABELS))\n",
    "nb_images_per_label = list(np.zeros(len(new_labels), 'uint8'))\n",
    "try:\n",
    "    os.makedirs(OUTPUT_FOLDER_NAME)\n",
    "except OSError as e:\n",
    "    if e.errno == errno.EEXIST and os.path.isdir(OUTPUT_FOLDER_NAME):\n",
    "        pass\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "def get_landmarks(image, rects):\n",
    "    # this function have been copied from http://bit.ly/2cj7Fpq\n",
    "    if len(rects) > 1:\n",
    "        raise BaseException(\"TooManyFaces\")\n",
    "    if len(rects) == 0:\n",
    "        raise BaseException(\"NoFaces\")\n",
    "    return np.matrix([[p.x, p.y] for p in predictor(image, rects[0]).parts()])\n",
    "\n",
    "def get_new_label(label, one_hot_encoding=False):\n",
    "    if one_hot_encoding:\n",
    "        new_label = new_labels.index(label)\n",
    "        label = list(np.zeros(len(new_labels), 'uint8'))\n",
    "        label[new_label] = 1\n",
    "        return label\n",
    "    else:\n",
    "        return new_labels.index(label)\n",
    "\n",
    "def sliding_hog_windows(image):\n",
    "    hog_windows = []\n",
    "    for y in range(0, image_height, window_step):\n",
    "        for x in range(0, image_width, window_step):\n",
    "            window = image[y:y+window_size, x:x+window_size]\n",
    "            hog_windows.extend(hog(window, orientations=8, pixels_per_cell=(8, 8),\n",
    "                                            cells_per_block=(1, 1), visualize=False))\n",
    "    return hog_windows\n",
    "\n",
    "print( \"importing csv file\")\n",
    "data = pd.read_csv('fer2013.csv')\n",
    "\n",
    "for category in data['Usage'].unique():\n",
    "    print( \"converting set: \" + category + \"...\")\n",
    "    # create folder\n",
    "    if not os.path.exists(category):\n",
    "        try:\n",
    "            os.makedirs(OUTPUT_FOLDER_NAME + '/' + category)\n",
    "        except OSError as e:\n",
    "            if e.errno == errno.EEXIST and os.path.isdir(OUTPUT_FOLDER_NAME):\n",
    "               pass\n",
    "            else:\n",
    "                raise\n",
    "    \n",
    "    # get samples and labels of the actual category\n",
    "    category_data = data[data['Usage'] == category]\n",
    "    samples = category_data['pixels'].values\n",
    "    labels = category_data['emotion'].values\n",
    "    \n",
    "    # get images and extract features\n",
    "    images = []\n",
    "    labels_list = []\n",
    "    landmarks = []\n",
    "    hog_features = []\n",
    "    hog_images = []\n",
    "    for i in range(len(samples)):\n",
    "        try:\n",
    "            if labels[i] in SELECTED_LABELS and nb_images_per_label[get_new_label(labels[i])] < IMAGES_PER_LABEL:\n",
    "                image = np.fromstring(samples[i], dtype=int, sep=\" \").reshape((image_height, image_width))\n",
    "                images.append(image)\n",
    "                if SAVE_IMAGES:\n",
    "                    imageio.imwrite(category + '/' + str(i) + '.jpg', image)\n",
    "                if GET_HOG_WINDOWS_FEATURES:\n",
    "                    features = sliding_hog_windows(image)\n",
    "                    f, hog_image = hog(image, orientations=8, pixels_per_cell=(16, 16),\n",
    "                                            cells_per_block=(1, 1), visualize=True)\n",
    "                    hog_features.append(features)\n",
    "                    hog_images.append(hog_image)\n",
    "                elif GET_HOG_FEATURES:\n",
    "                    features, hog_image = hog(image, orientations=8, pixels_per_cell=(16, 16),\n",
    "                                            cells_per_block=(1, 1), visualize=True)\n",
    "                    hog_features.append(features)\n",
    "                    hog_images.append(hog_image)\n",
    "                if GET_LANDMARKS:\n",
    "                    imageio.imwrite('temp.jpg', image)\n",
    "                    image2 = cv2.imread('temp.jpg')\n",
    "                    face_rects = [dlib.rectangle(left=1, top=1, right=47, bottom=47)]\n",
    "                    face_landmarks = get_landmarks(image2, face_rects)\n",
    "                    landmarks.append(face_landmarks)            \n",
    "                labels_list.append(get_new_label(labels[i], one_hot_encoding=ONE_HOT_ENCODING))\n",
    "                nb_images_per_label[get_new_label(labels[i])] += 1\n",
    "        except Exception as e:\n",
    "            print( \"error in image: \" + str(i) + \" - \" + str(e))\n",
    "\n",
    "    np.save(OUTPUT_FOLDER_NAME + '/' + category + '/images.npy', images)\n",
    "    if ONE_HOT_ENCODING:\n",
    "        np.save(OUTPUT_FOLDER_NAME + '/' + category + '/labels.npy', labels_list)\n",
    "    else:\n",
    "        np.save(OUTPUT_FOLDER_NAME + '/' + category + '/labels.npy', labels_list)\n",
    "    if GET_LANDMARKS:\n",
    "        np.save(OUTPUT_FOLDER_NAME + '/' + category + '/landmarks.npy', landmarks)\n",
    "    if GET_HOG_FEATURES or GET_HOG_WINDOWS_FEATURES:\n",
    "        np.save(OUTPUT_FOLDER_NAME + '/' + category + '/hog_features.npy', hog_features)\n",
    "        np.save(OUTPUT_FOLDER_NAME + '/' + category + '/hog_images.npy', hog_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from parameters import DATASET, HYPERPARAMS\n",
    "import numpy as np\n",
    "\n",
    "def load_data(validation=False, test=False):\n",
    "    \n",
    "    data_dict = dict()\n",
    "    validation_dict = dict()\n",
    "    test_dict = dict()\n",
    "\n",
    "    if DATASET.name == \"Fer2013\":\n",
    "        # load train set\n",
    "        if HYPERPARAMS.features == \"landmarks_and_hog\":\n",
    "            data_dict['X'] = np.load(DATASET.train_folder + '/landmarks.npy')\n",
    "            data_dict['X'] = np.array([x.flatten() for x in data_dict['X']])\n",
    "            data_dict['X'] = np.concatenate((data_dict['X'], np.load(DATASET.train_folder + '/hog_features.npy')),axis=1)\n",
    "        elif HYPERPARAMS.features == \"landmarks\":\n",
    "            data_dict['X'] = np.load(DATASET.train_folder + '/landmarks.npy')\n",
    "            data_dict['X'] = np.array([x.flatten() for x in data_dict['X']])\n",
    "        elif HYPERPARAMS.features == \"hog\":\n",
    "            data_dict['X'] = np.load(DATASET.train_folder + '/hog_features.npy')\n",
    "        else:\n",
    "            print( \"Error '{}' features not recognized\".format(HYPERPARAMS.features))\n",
    "        data_dict['Y'] = np.load(DATASET.train_folder + '/labels.npy')\n",
    "        if DATASET.trunc_trainset_to > 0:\n",
    "            data_dict['X'] = data_dict['X'][0:DATASET.trunc_trainset_to, :]\n",
    "            data_dict['Y'] = data_dict['Y'][0:DATASET.trunc_trainset_to]\n",
    "        if validation:\n",
    "            # load validation set \n",
    "            if HYPERPARAMS.features == \"landmarks_and_hog\":\n",
    "                validation_dict['X'] = np.load(DATASET.validation_folder + '/landmarks.npy')\n",
    "                validation_dict['X'] = np.array([x.flatten() for x in validation_dict['X']])\n",
    "                validation_dict['X'] = np.concatenate((validation_dict['X'], np.load(DATASET.validation_folder + '/hog_features.npy')),axis=1)\n",
    "            elif HYPERPARAMS.features == \"landmarks\":\n",
    "                validation_dict['X'] = np.load(DATASET.validation_folder + '/landmarks.npy')\n",
    "                validation_dict['X'] = np.array([x.flatten() for x in validation_dict['X']])\n",
    "            elif HYPERPARAMS.features == \"hog\":\n",
    "                validation_dict['X'] = np.load(DATASET.validation_folder + '/hog_features.npy')\n",
    "            else:\n",
    "                print( \"Error '{}' features not recognized\".format(HYPERPARAMS.features))\n",
    "            validation_dict['Y'] = np.load(DATASET.validation_folder + '/labels.npy')\n",
    "            if DATASET.trunc_validationset_to > 0:\n",
    "                validation_dict['X'] = validation_dict['X'][0:DATASET.trunc_validationset_to, :]\n",
    "                validation_dict['Y'] = validation_dict['Y'][0:DATASET.trunc_validationset_to]\n",
    "        if test:\n",
    "            # load train set\n",
    "            if HYPERPARAMS.features == \"landmarks_and_hog\":\n",
    "                test_dict['X'] = np.load(DATASET.test_folder + '/landmarks.npy')\n",
    "                test_dict['X'] = np.array([x.flatten() for x in test_dict['X']])\n",
    "                test_dict['X'] = np.concatenate((test_dict['X'], np.load(DATASET.test_folder + '/hog_features.npy')), axis=1)\n",
    "            elif HYPERPARAMS.features == \"landmarks\":\n",
    "                test_dict['X'] = np.load(DATASET.test_folder + '/landmarks.npy')\n",
    "                test_dict['X'] = np.array([x.flatten() for x in test_dict['X']])\n",
    "            elif HYPERPARAMS.features == \"hog\":\n",
    "                test_dict['X'] = np.load(DATASET.test_folder + '/hog_features.npy')\n",
    "            else:\n",
    "                print( \"Error '{}' features not recognized\".format(HYPERPARAMS.features))\n",
    "            test_dict['Y'] = np.load(DATASET.test_folder + '/labels.npy')\n",
    "            np.save(DATASET.test_folder + \"/lab.npy\", test_dict['Y'])\n",
    "            if DATASET.trunc_testset_to > 0:\n",
    "                test_dict['X'] = test_dict['X'][0:DATASET.trunc_testset_to, :]\n",
    "                test_dict['Y'] = test_dict['Y'][0:DATASET.trunc_testset_to]\n",
    "\n",
    "        if not validation and not test:\n",
    "            return data_dict\n",
    "        elif not test:\n",
    "            return data_dict, validation_dict\n",
    "        else: \n",
    "            return data_dict, validation_dict, test_dict\n",
    "    else:\n",
    "        print( \"Unknown dataset\")\n",
    "        exit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset Fer2013...\n",
      "building model...\n",
      "start training...\n",
      "--\n",
      "kernel: linear\n",
      "decision function: ovr \n",
      "max epochs: 10000 \n",
      "gamma: auto \n",
      "--\n",
      "Training samples: 3436\n",
      "Validation samples: 56\n",
      "--\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time = 27.3 sec\n",
      "saving model...\n",
      "evaluating...\n",
      "  - validation accuracy = 48.2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.48214285714285715"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "if sys.version_info >= (3, 0):\n",
    "        import _pickle as cPickle\n",
    "else:\n",
    "        import cPickle\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from data_loader import load_data \n",
    "from parameters import DATASET, TRAINING, HYPERPARAMS\n",
    "\n",
    "def train(epochs=HYPERPARAMS.epochs, random_state=HYPERPARAMS.random_state, \n",
    "          kernel=\"linear\", decision_function=HYPERPARAMS.decision_function, gamma=HYPERPARAMS.gamma, train_model=True):\n",
    "\n",
    "        print( \"loading dataset \" + DATASET.name + \"...\")\n",
    "        if train_model:\n",
    "                data, validation = load_data(validation=True)\n",
    "        else:\n",
    "                data, validation, test = load_data(validation=True, test=True)\n",
    "        \n",
    "        if train_model:\n",
    "            # Training phase\n",
    "            print( \"building model...\")\n",
    "            model = SVC(random_state=random_state, max_iter=1000, kernel=\"linear\", decision_function_shape=decision_function, gamma=gamma)\n",
    "\n",
    "            print( \"start training...\")\n",
    "            print( \"--\")\n",
    "            print( \"kernel: {}\".format(kernel))\n",
    "            print( \"decision function: {} \".format(decision_function))\n",
    "            print( \"max epochs: {} \".format(epochs))\n",
    "            print( \"gamma: {} \".format(gamma))\n",
    "            print( \"--\")\n",
    "            print( \"Training samples: {}\".format(len(data['Y'])))\n",
    "            print( \"Validation samples: {}\".format(len(validation['Y'])))\n",
    "            print( \"--\")\n",
    "            start_time = time.time()\n",
    "            model.fit(data['X'], data['Y'])\n",
    "            training_time = time.time() - start_time\n",
    "            print( \"training time = {0:.1f} sec\".format(training_time))\n",
    "\n",
    "            if TRAINING.save_model:\n",
    "                print( \"saving model...\")\n",
    "                with open(TRAINING.save_model_path, 'wb') as f:\n",
    "                        cPickle.dump(model, f)\n",
    "\n",
    "            print( \"evaluating...\")\n",
    "            validation_accuracy = evaluate(model, validation['X'], validation['Y'])\n",
    "            print( \"  - validation accuracy = {0:.1f}\".format(validation_accuracy*100))\n",
    "            return validation_accuracy\n",
    "        else:\n",
    "            # Testing phase : load saved model and evaluate on test dataset\n",
    "            print( \"start evaluation...\")\n",
    "            print( \"loading pretrained model...\")\n",
    "            if os.path.isfile(TRAINING.save_model_path):\n",
    "                with open(TRAINING.save_model_path, 'rb') as f:\n",
    "                        model = cPickle.load(f)\n",
    "            else:\n",
    "                print( \"Error: file '{}' not found\".format(TRAINING.save_model_path))\n",
    "                exit()\n",
    "\n",
    "            print( \"--\")\n",
    "            print( \"Validation samples: {}\".format(len(validation['Y'])))\n",
    "            print( \"Test samples: {}\".format(len(test['Y'])))\n",
    "            print( \"--\")\n",
    "            print( \"evaluating...\")\n",
    "            start_time = time.time()\n",
    "            validation_accuracy = evaluate(model, validation['X'],  validation['Y'])\n",
    "            print( \"  - validation accuracy = {0:.1f}\".format(validation_accuracy*100))\n",
    "            test_accuracy = evaluate(model, test['X'], test['Y'])\n",
    "            print( \"  - test accuracy = {0:.1f}\".format(test_accuracy*100))\n",
    "            print( \"  - evalution time = {0:.1f} sec\".format(time.time() - start_time))\n",
    "           \n",
    "            return test_accuracy\n",
    "\n",
    "def evaluate(model, X, Y):\n",
    "        predicted_Y = model.predict(X)\n",
    "        accuracy = accuracy_score(Y, predicted_Y)\n",
    "        return accuracy\n",
    "\n",
    "train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset Fer2013...\n",
      "start evaluation...\n",
      "loading pretrained model...\n",
      "--\n",
      "Validation samples: 56\n",
      "Test samples: 8\n",
      "--\n",
      "evaluating...\n",
      "  - validation accuracy = 48.2\n",
      "  - test accuracy = 62.5\n",
      "  - evalution time = 1.1 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(train_model=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################################                     \n",
      "       Evaluation 1 of 15                             \n",
      "#################################                     \n",
      "loading dataset Fer2013...                            \n",
      "building model...                                     \n",
      "start training...                                     \n",
      "--                                                    \n",
      "kernel: rbf                                           \n",
      "decision function: ovr                                \n",
      "max epochs: 500                                       \n",
      "gamma: 0.009508275768257215                           \n",
      "--                                                    \n",
      "Training samples: 3436                                \n",
      "Validation samples: 56                                \n",
      "--                                                    \n",
      "training time = 47.4 sec                              \n",
      "saving model...                                       \n",
      "  0%|          | 0/15 [00:47<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...                                         \n",
      "  - validation accuracy = 39.3                        \n",
      "#################################                                                 \n",
      "       Evaluation 2 of 15                                                         \n",
      "#################################                                                 \n",
      "loading dataset Fer2013...                                                        \n",
      "building model...                                                                 \n",
      "start training...                                                                 \n",
      "--                                                                                \n",
      "kernel: rbf                                                                       \n",
      "decision function: ovo                                                            \n",
      "max epochs: 500                                                                   \n",
      "gamma: 0.0049653069759365166                                                      \n",
      "--                                                                                \n",
      "Training samples: 3436                                                            \n",
      "Validation samples: 56                                                            \n",
      "--                                                                                \n",
      "training time = 49.4 sec                                                          \n",
      "saving model...                                                                   \n",
      "  7%|▋         | 1/15 [01:38<11:22, 48.77s/trial, best loss: -0.39285714285714285]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...                                                                     \n",
      "  - validation accuracy = 46.4                                                    \n",
      "#################################                                                 \n",
      "       Evaluation 3 of 15                                                        \n",
      "#################################                                                \n",
      "loading dataset Fer2013...                                                       \n",
      "building model...                                                                \n",
      "start training...                                                                \n",
      "--                                                                               \n",
      "kernel: rbf                                                                      \n",
      "decision function: ovo                                                           \n",
      "max epochs: 500                                                                  \n",
      "gamma: 0.004547225645052288                                                      \n",
      "--                                                                               \n",
      "Training samples: 3436                                                           \n",
      "Validation samples: 56                                                           \n",
      "--                                                                               \n",
      "training time = 47.5 sec                                                         \n",
      "saving model...                                                                  \n",
      " 13%|█▎        | 2/15 [02:27<10:50, 50.02s/trial, best loss: -0.4642857142857143]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...                                                                    \n",
      "  - validation accuracy = 46.4                                                   \n",
      "#################################                                                \n",
      "       Evaluation 4 of 15                                                        \n",
      "#################################                                                \n",
      "loading dataset Fer2013...                                                       \n",
      "building model...                                                                \n",
      "start training...                                                                \n",
      "--                                                                               \n",
      "kernel: rbf                                                                      \n",
      "decision function: ovr                                                           \n",
      "max epochs: 500                                                                  \n",
      "gamma: 0.004095022276109191                                                      \n",
      "--                                                                               \n",
      "Training samples: 3436                                                           \n",
      "Validation samples: 56                                                           \n",
      "--                                                                               \n",
      "training time = 43.9 sec                                                         \n",
      "saving model...                                                                  \n",
      " 20%|██        | 3/15 [03:12<09:53, 49.47s/trial, best loss: -0.4642857142857143]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...                                                                    \n",
      "  - validation accuracy = 46.4                                                   \n",
      "#################################                                                \n",
      "       Evaluation 5 of 15                                                        \n",
      "#################################                                                \n",
      "loading dataset Fer2013...                                                       \n",
      "building model...                                                                \n",
      "start training...                                                                \n",
      "--                                                                               \n",
      "kernel: rbf                                                                      \n",
      "decision function: ovo                                                           \n",
      "max epochs: 500                                                                  \n",
      "gamma: 0.0033551531946083924                                                     \n",
      "--                                                                               \n",
      "Training samples: 3436                                                           \n",
      "Validation samples: 56                                                           \n",
      "--                                                                               \n",
      "training time = 44.2 sec                                                         \n",
      "saving model...                                                                  \n",
      " 27%|██▋       | 4/15 [03:58<08:45, 47.81s/trial, best loss: -0.4642857142857143]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...                                                                    \n",
      "  - validation accuracy = 50.0                                                   \n",
      "#################################                                                \n",
      "       Evaluation 6 of 15                                         \n",
      "#################################                                 \n",
      "loading dataset Fer2013...                                        \n",
      "building model...                                                 \n",
      "start training...                                                 \n",
      "--                                                                \n",
      "kernel: rbf                                                       \n",
      "decision function: ovr                                            \n",
      "max epochs: 500                                                   \n",
      "gamma: 0.005007077882982711                                       \n",
      "--                                                                \n",
      "Training samples: 3436                                            \n",
      "Validation samples: 56                                            \n",
      "--                                                                \n",
      "training time = 39.1 sec                                          \n",
      "saving model...                                                   \n",
      " 33%|███▎      | 5/15 [04:38<07:49, 46.94s/trial, best loss: -0.5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...                                                     \n",
      "  - validation accuracy = 46.4                                    \n",
      "#################################                                 \n",
      "       Evaluation 7 of 15                                         \n",
      "#################################                                 \n",
      "loading dataset Fer2013...                                        \n",
      "building model...                                                 \n",
      "start training...                                                 \n",
      "--                                                                \n",
      "kernel: rbf                                                       \n",
      "decision function: ovo                                            \n",
      "max epochs: 500                                                   \n",
      "gamma: 0.006919568848586376                                       \n",
      "--                                                                \n",
      "Training samples: 3436                                            \n",
      "Validation samples: 56                                            \n",
      "--                                                                \n",
      "training time = 40.5 sec                                          \n",
      "saving model...                                                   \n",
      " 40%|████      | 6/15 [05:20<06:42, 44.68s/trial, best loss: -0.5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...                                                     \n",
      "  - validation accuracy = 42.9                                    \n",
      "#################################                                 \n",
      "       Evaluation 8 of 15                                         \n",
      "#################################                                 \n",
      "loading dataset Fer2013...                                        \n",
      "building model...                                                 \n",
      "start training...                                                 \n",
      "--                                                                \n",
      "kernel: rbf                                                       \n",
      "decision function: ovr                                            \n",
      "max epochs: 500                                                   \n",
      "gamma: 0.007204466450877652                                       \n",
      "--                                                                \n",
      "Training samples: 3436                                            \n",
      "Validation samples: 56                                            \n",
      "--                                                                \n",
      "training time = 40.5 sec                                          \n",
      "saving model...                                                   \n",
      " 47%|████▋     | 7/15 [06:01<05:49, 43.68s/trial, best loss: -0.5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...                                                     \n",
      "  - validation accuracy = 42.9                                    \n",
      "#################################                                 \n",
      "       Evaluation 9 of 15                                         \n",
      "#################################                                 \n",
      "loading dataset Fer2013...                                        \n",
      "building model...                                                 \n",
      "start training...                                                 \n",
      "--                                                                \n",
      "kernel: rbf                                                       \n",
      "decision function: ovo                                            \n",
      "max epochs: 500                                                   \n",
      "gamma: 0.005134535164510164                                       \n",
      "--                                                                \n",
      "Training samples: 3436                                            \n",
      "Validation samples: 56                                            \n",
      "--                                                                \n",
      "training time = 39.1 sec                                          \n",
      "saving model...                                                   \n",
      " 53%|█████▎    | 8/15 [06:42<05:01, 43.03s/trial, best loss: -0.5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...                                                     \n",
      "  - validation accuracy = 44.6                                    \n",
      "#################################                                 \n",
      "       Evaluation 10 of 15                                        \n",
      "#################################                                 \n",
      "loading dataset Fer2013...                                        \n",
      "building model...                                                 \n",
      "start training...                                                 \n",
      "--                                                                \n",
      "kernel: rbf                                                       \n",
      "decision function: ovr                                            \n",
      "max epochs: 500                                                   \n",
      "gamma: 0.008191798146045853                                       \n",
      "--                                                                \n",
      "Training samples: 3436                                            \n",
      "Validation samples: 56                                            \n",
      "--                                                                \n",
      "training time = 44.3 sec                                          \n",
      "saving model...                                                   \n",
      " 60%|██████    | 9/15 [07:27<04:12, 42.15s/trial, best loss: -0.5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...                                                     \n",
      "  - validation accuracy = 41.1                                    \n",
      "#################################                                  \n",
      "       Evaluation 11 of 15                                         \n",
      "#################################                                  \n",
      "loading dataset Fer2013...                                         \n",
      "building model...                                                  \n",
      "start training...                                                  \n",
      "--                                                                 \n",
      "kernel: rbf                                                        \n",
      "decision function: ovo                                             \n",
      "max epochs: 500                                                    \n",
      "gamma: 0.00980673410426254                                         \n",
      "--                                                                 \n",
      "Training samples: 3436                                             \n",
      "Validation samples: 56                                             \n",
      "--                                                                 \n",
      "training time = 51.2 sec                                           \n",
      "saving model...                                                    \n",
      " 67%|██████▋   | 10/15 [08:20<03:36, 43.28s/trial, best loss: -0.5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...                                                      \n",
      "  - validation accuracy = 39.3                                     \n",
      "#################################                                  \n",
      "       Evaluation 12 of 15                                         \n",
      "#################################                                  \n",
      "loading dataset Fer2013...                                         \n",
      "building model...                                                  \n",
      "start training...                                                  \n",
      "--                                                                 \n",
      "kernel: rbf                                                        \n",
      "decision function: ovr                                             \n",
      "max epochs: 500                                                    \n",
      "gamma: 0.009569601367579901                                        \n",
      "--                                                                 \n",
      "Training samples: 3436                                             \n",
      "Validation samples: 56                                             \n",
      "--                                                                 \n",
      "training time = 41.5 sec                                           \n",
      "saving model...                                                    \n",
      " 73%|███████▎  | 11/15 [09:02<03:04, 46.10s/trial, best loss: -0.5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...                                                      \n",
      "  - validation accuracy = 39.3                                     \n",
      "#################################                                  \n",
      "       Evaluation 13 of 15                                         \n",
      "#################################                                  \n",
      "loading dataset Fer2013...                                         \n",
      "building model...                                                  \n",
      "start training...                                                  \n",
      "--                                                                 \n",
      "kernel: rbf                                                        \n",
      "decision function: ovr                                             \n",
      "max epochs: 500                                                    \n",
      "gamma: 0.0049211784428082475                                       \n",
      "--                                                                 \n",
      "Training samples: 3436                                             \n",
      "Validation samples: 56                                             \n",
      "--                                                                 \n",
      "training time = 46.4 sec                                           \n",
      "saving model...                                                    \n",
      " 80%|████████  | 12/15 [09:50<02:15, 45.07s/trial, best loss: -0.5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...                                                      \n",
      "  - validation accuracy = 46.4                                     \n",
      "#################################                                  \n",
      "       Evaluation 14 of 15                                         \n",
      "#################################                                  \n",
      "loading dataset Fer2013...                                         \n",
      "building model...                                                  \n",
      "start training...                                                  \n",
      "--                                                                 \n",
      "kernel: rbf                                                        \n",
      "decision function: ovo                                             \n",
      "max epochs: 500                                                    \n",
      "gamma: 0.008623658327332721                                        \n",
      "--                                                                 \n",
      "Training samples: 3436                                             \n",
      "Validation samples: 56                                             \n",
      "--                                                                 \n",
      "training time = 46.9 sec                                           \n",
      "saving model...                                                    \n",
      " 87%|████████▋ | 13/15 [10:38<01:31, 45.84s/trial, best loss: -0.5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...                                                      \n",
      "  - validation accuracy = 41.1                                     \n",
      "#################################                                  \n",
      "       Evaluation 15 of 15                                         \n",
      "#################################                                  \n",
      "loading dataset Fer2013...                                         \n",
      "building model...                                                  \n",
      "start training...                                                  \n",
      "--                                                                 \n",
      "kernel: rbf                                                        \n",
      "decision function: ovr                                             \n",
      "max epochs: 500                                                    \n",
      "gamma: 0.0011559970127537034                                       \n",
      "--                                                                 \n",
      "Training samples: 3436                                             \n",
      "Validation samples: 56                                             \n",
      "--                                                                 \n",
      "training time = 36.8 sec                                           \n",
      "saving model...                                                    \n",
      " 93%|█████████▎| 14/15 [11:16<00:46, 46.56s/trial, best loss: -0.5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating...                                                      \n",
      "  - validation accuracy = 51.8                                     \n",
      "100%|██████████| 15/15 [11:17<00:00, 45.19s/trial, best loss: -0.5178571428571429]\n",
      "#################################\n",
      "      Best parameters found\n",
      "#################################\n",
      "{'accuracy': 51.78571428571429,\n",
      " 'decision_function': 0,\n",
      " 'gamma': 0.0011559970127537034,\n",
      " 'time': 38}\n",
      "decision_function { 0: ovr, 1: ovo }\n",
      "#################################\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import argparse\n",
    "import pprint\n",
    "import numpy as np \n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "import sys\n",
    "sys.argv=['']\n",
    "del sys\n",
    "from train import train\n",
    "from parameters import HYPERPARAMS\n",
    "\n",
    "# define the search space\n",
    "fspace = {\n",
    "    'decision_function': hp.choice('decision_function', ['ovr', 'ovo']),\n",
    "    'gamma':  hp.uniform('gamma', 0.001, 0.01)\n",
    "}\n",
    "\n",
    "# parse arguments\n",
    "\n",
    "max_evals = 15\n",
    "current_eval = 1\n",
    "train_history = []\n",
    "\n",
    "def function_to_minimize(hyperparams, gamma='auto', decision_function='ovr'):\n",
    "    decision_function = hyperparams['decision_function']\n",
    "    gamma = hyperparams['gamma']\n",
    "    global current_eval \n",
    "    global max_evals\n",
    "    print( \"#################################\")\n",
    "    print( \"       Evaluation {} of {}\".format(current_eval, max_evals))\n",
    "    print( \"#################################\")\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        accuracy = train(epochs=HYPERPARAMS.epochs_during_hyperopt, decision_function=decision_function, gamma=gamma)\n",
    "        training_time = int(round(time.time() - start_time))\n",
    "        current_eval += 1\n",
    "        train_history.append({'accuracy':accuracy, 'decision_function':decision_function, 'gamma':gamma, 'time':training_time})\n",
    "    except Exception as e:\n",
    "        print( \"#################################\")\n",
    "        print( \"Exception during training: {}\".format(str(e)))\n",
    "        print( \"Saving train history in train_history.npy\")\n",
    "        np.save(\"train_history.npy\", train_history)\n",
    "        exit()\n",
    "    return {'loss': -accuracy, 'time': training_time, 'status': STATUS_OK}\n",
    "\n",
    "# lunch the hyperparameters search\n",
    "trials = Trials()\n",
    "best_trial = fmin(fn=function_to_minimize, space=fspace, algo=tpe.suggest, max_evals=max_evals, trials=trials)\n",
    "\n",
    "# get some additional information and print( the best parameters\n",
    "for trial in trials.trials:\n",
    "    if trial['misc']['vals']['decision_function'][0] == best_trial['decision_function'] and \\\n",
    "            trial['misc']['vals']['gamma'][0] == best_trial['gamma']:\n",
    "        best_trial['accuracy'] = -trial['result']['loss'] * 100\n",
    "        best_trial['time'] = trial['result']['time']\n",
    "print( \"#################################\")\n",
    "print( \"      Best parameters found\")\n",
    "print( \"#################################\")         \n",
    "pprint.pprint(best_trial)\n",
    "print( \"decision_function { 0: ovr, 1: ovo }\")\n",
    "print( \"#################################\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hog features (56, 2592)\n",
      "hog images (56, 48, 48)\n",
      "images (56, 48, 48)\n",
      "labels (56,)\n",
      "landmarks (56, 68, 2)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "data1 = np.load('C:/Vscode/VIT_Code/4th_sem/ML-J Comp/fer2013_features/PublicTest/hog_features.npy')\n",
    "print(\"hog features\",data1.shape)\n",
    "data2 = np.load('C:/Vscode/VIT_Code/4th_sem/ML-J Comp/fer2013_features/PublicTest/hog_images.npy')\n",
    "print(\"hog images\",data2.shape)\n",
    "data3 = np.load('C:/Vscode/VIT_Code/4th_sem/ML-J Comp/fer2013_features/PublicTest/images.npy')\n",
    "print(\"images\",data3.shape)\n",
    "data4 = np.load('C:/Vscode/VIT_Code/4th_sem/ML-J Comp/fer2013_features/PublicTest/labels.npy')\n",
    "print(\"labels\",data4.shape)\n",
    "data5 = np.load('C:/Vscode/VIT_Code/4th_sem/ML-J Comp/fer2013_features/PublicTest/landmarks.npy')\n",
    "print(\"landmarks\",data5.shape)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bfb4883d108fc92ac768439090a2e92bb9a1f760a54beeecfd6762b5dcd70fe3"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
